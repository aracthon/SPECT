{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-51-0013b265a18f>:80 in main.: initialize_all_variables (from tensorflow.python.ops.variables) is deprecated and will be removed after 2017-03-02.\n",
      "Instructions for updating:\n",
      "Use `tf.global_variables_initializer` instead.\n",
      "Initialized!\n",
      "\n",
      "Training.\n",
      "0 loss:  1.48903\n",
      "1 loss:  1.46964\n",
      "2 loss:  1.51648\n",
      "3 loss:  1.66452\n",
      "4 loss:  1.63505\n",
      "\n",
      "5 loss:  1.37186\n",
      "6 loss:  1.40452\n",
      "7 loss:  1.4657\n",
      "8 loss:  1.69438\n",
      "9 loss:  1.67001\n",
      "\n",
      "10 loss:  1.26203\n",
      "11 loss:  1.34415\n",
      "12 loss:  1.41894\n",
      "13 loss:  1.72427\n",
      "14 loss:  1.70472\n",
      "\n",
      "15 loss:  1.15902\n",
      "16 loss:  1.28815\n",
      "17 loss:  1.37585\n",
      "18 loss:  1.75406\n",
      "19 loss:  1.73907\n",
      "\n",
      "20 loss:  1.06236\n",
      "21 loss:  1.23617\n",
      "22 loss:  1.33613\n",
      "23 loss:  1.78361\n",
      "24 loss:  1.77293\n",
      "\n",
      "25 loss:  0.971623\n",
      "26 loss:  1.1879\n",
      "27 loss:  1.29948\n",
      "28 loss:  1.81282\n",
      "29 loss:  1.80622\n",
      "\n",
      "30 loss:  0.886397\n",
      "31 loss:  1.14304\n",
      "32 loss:  1.26566\n",
      "33 loss:  1.84161\n",
      "34 loss:  1.83887\n",
      "\n",
      "35 loss:  0.806312\n",
      "36 loss:  1.10132\n",
      "37 loss:  1.24305\n",
      "38 loss:  1.86455\n",
      "39 loss:  1.86467\n",
      "\n",
      "40 loss:  0.750082\n",
      "41 loss:  1.06893\n",
      "42 loss:  1.23959\n",
      "43 loss:  1.87731\n",
      "44 loss:  1.87976\n",
      "\n",
      "45 loss:  0.723046\n",
      "46 loss:  1.0558\n",
      "47 loss:  1.2382\n",
      "48 loss:  1.8845\n",
      "49 loss:  1.88868\n",
      "\n",
      "\n",
      "Weight matrix.\n",
      "[[ 0.04692209]\n",
      " [ 0.04764615]\n",
      " [ 0.06153021]\n",
      " [ 0.0650437 ]\n",
      " [ 0.02466021]\n",
      " [ 0.02873225]\n",
      " [ 0.07916395]\n",
      " [ 0.10262739]\n",
      " [ 0.04835835]\n",
      " [ 0.05043159]\n",
      " [ 0.07278399]\n",
      " [ 0.06966867]\n",
      " [ 0.13183914]\n",
      " [ 0.05609785]\n",
      " [ 0.03008436]\n",
      " [ 0.08594558]\n",
      " [ 0.05873876]\n",
      " [ 0.04198079]\n",
      " [ 0.03527337]\n",
      " [ 0.05690126]\n",
      " [ 0.07932273]\n",
      " [ 0.0846003 ]]\n",
      "\n",
      "Bias vector.\n",
      "[-0.008]\n",
      "\n",
      "Applying model to first test instance.\n",
      "\n",
      "Accuracy on train: 0.935829\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import scipy.io as io\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Global variables.\n",
    "BATCH_SIZE = 16  # The number of training examples to use per training step.\n",
    "\n",
    "def extract_data(filename):\n",
    "\n",
    "    out = np.loadtxt(filename, delimiter=',');\n",
    "\n",
    "    # Arrays to hold the labels and feature vectors.\n",
    "    labels = out[:,0]\n",
    "    labels = labels.reshape(labels.size,1)\n",
    "    fvecs = out[:,1:]\n",
    "\n",
    "    # Return a pair of the feature matrix and the one-hot label matrix.\n",
    "    return fvecs,labels\n",
    "\n",
    "\n",
    "def main(argv=None):\n",
    "    # Be verbose?\n",
    "    verbose = True\n",
    "\n",
    "    # Plot? \n",
    "    plot = False\n",
    "    \n",
    "    # Get the data.\n",
    "    train_data_filename = '../data/SPECT.train.txt'\n",
    "    test_data_filename = '../data/SPECT.test.txt'\n",
    "\n",
    "    # Extract it into numpy matrices.\n",
    "    train_data, train_labels = extract_data(train_data_filename)\n",
    "    test_data, test_labels = extract_data(test_data_filename)\n",
    "\n",
    "    # Convert labels to +1,-1\n",
    "    train_labels[train_labels==0] = -1\n",
    "    test_labels[test_labels==0] = -1\n",
    "\n",
    "    # Get the shape of the training data.\n",
    "    train_size, num_features = train_data.shape\n",
    "    test_size, num_features = test_data.shape\n",
    "\n",
    "    # Get the number of epochs for training.\n",
    "    num_epochs = 10\n",
    "\n",
    "    # Get the C param of SVM\n",
    "    svmC = 0.1#FLAGS.svmC\n",
    "\n",
    "    # This is where training samples and labels are fed to the graph.\n",
    "    # These placeholder nodes will be fed a batch of training data at each\n",
    "    # training step using the {feed_dict} argument to the Run() call below.\n",
    "    x = tf.placeholder(\"float\", shape=[None, num_features])\n",
    "    y = tf.placeholder(\"float\", shape=[None,1])\n",
    "\n",
    "    # Define and initialize the network.\n",
    "\n",
    "    # These are the weights that inform how much each feature contributes to\n",
    "    # the classification.\n",
    "    W = tf.Variable(tf.zeros([num_features,1]))\n",
    "    b = tf.Variable(tf.zeros([1]))\n",
    "    y_raw = tf.matmul(x,W) + b\n",
    "\n",
    "    # Optimization.\n",
    "    regularization_loss = 0.5*tf.reduce_sum(tf.square(W)) \n",
    "    hinge_loss = tf.reduce_sum(tf.maximum(tf.zeros([BATCH_SIZE,1]), \n",
    "        1 - y*y_raw));\n",
    "    svm_loss = regularization_loss + svmC*hinge_loss;\n",
    "    train_step = tf.train.GradientDescentOptimizer(0.01).minimize(svm_loss)\n",
    "\n",
    "    # Evaluation.\n",
    "    predicted_class = tf.sign(y_raw);\n",
    "    correct_prediction = tf.equal(y,predicted_class)\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_prediction, \"float\"))\n",
    "\n",
    "    # Create a local session to run this computation.\n",
    "    with tf.Session() as s:\n",
    "        # Run all the initializers to prepare the trainable parameters.\n",
    "        tf.initialize_all_variables().run()\n",
    "        if verbose:\n",
    "            print 'Initialized!'\n",
    "            print\n",
    "            print 'Training.'\n",
    "\n",
    "        # Iterate and train.\n",
    "        for step in xrange(num_epochs * train_size // BATCH_SIZE):\n",
    "            if verbose:\n",
    "                print step,\n",
    "\n",
    "            offset = (step * BATCH_SIZE) % train_size\n",
    "            batch_data = train_data[offset:(offset + BATCH_SIZE), :]\n",
    "            batch_labels = train_labels[offset:(offset + BATCH_SIZE)]\n",
    "            train_step.run(feed_dict={x: batch_data, y: batch_labels})\n",
    "            print 'loss: ', svm_loss.eval(feed_dict={x: batch_data, y: batch_labels})\n",
    "\n",
    "            if verbose and offset >= train_size-BATCH_SIZE:\n",
    "                print\n",
    "\n",
    "        # Give very detailed output.\n",
    "        if verbose:\n",
    "            print\n",
    "            print 'Weight matrix.'\n",
    "            print s.run(W)\n",
    "            print\n",
    "            print 'Bias vector.'\n",
    "            print s.run(b)\n",
    "            print\n",
    "            print \"Applying model to first test instance.\"\n",
    "            print\n",
    "            \n",
    "        print \"Accuracy on train:\", accuracy.eval(feed_dict={x: test_data, y: test_labels})\n",
    "        \n",
    "        # test\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "    main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
